{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "385cb12c-eedf-4fa8-bd3d-5ec9ce15e21b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def read_bronze(table_name: str):\n",
    "    return dlt.read(table_name)\n",
    "\n",
    "def clean_int(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(F.col(col_name).cast(\"int\"))\n",
    "    )\n",
    "\n",
    "def clean_double(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(F.col(col_name).cast(\"double\"))\n",
    "    )\n",
    "\n",
    "def clean_string(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(F.col(col_name))\n",
    "    )\n",
    "def clean_name_or_title(col_name: str):\n",
    "  \n",
    "    return (\n",
    "        F.when(\n",
    "            (F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"),\n",
    "            None\n",
    "        ).otherwise(\n",
    "            F.trim(\n",
    "                F.regexp_replace(\n",
    "                    F.col(col_name),\n",
    "                    r'^[^A-Za-z0-9]+',   # remove garbage at the START only\n",
    "                    ''\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def split_list(col_name: str):\n",
    "    return F.when(\n",
    "        (F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"),\n",
    "        None,\n",
    "    ).otherwise(F.split(F.col(col_name), \",\"))\n",
    "\n",
    "def add_metadata(df, source_table: str):\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"src_table\", F.lit(source_table))\n",
    "        .withColumn(\"load_ts\", F.current_timestamp())\n",
    "        .withColumn(\"loaded_by\", F.current_user())\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2473c66-63a1-47c7-9664-0070ed134b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_name_basics\",\n",
    "    comment=\"Cleaned personnel master (names, birth/death, professions, known-for titles).\"\n",
    ")\n",
    "def silver_name_basics():\n",
    "    df = read_bronze(\"bronze_name_basics\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # âœ… changed HERE\n",
    "        .withColumn(\"primaryName\",  clean_name_or_title(\"primaryName\"))\n",
    "        .withColumn(\"birthYear\",    clean_int(\"birthYear\"))\n",
    "        .withColumn(\"deathYear\",    clean_int(\"deathYear\"))\n",
    "\n",
    "        .withColumn(\"primaryProfession_arr\", split_list(\"primaryProfession\"))\n",
    "        .withColumn(\n",
    "            \"primaryProfession\",\n",
    "            F.when(\n",
    "                F.col(\"primaryProfession_arr\").isNull(),\n",
    "                None\n",
    "            ).otherwise(F.concat_ws(\", \", F.col(\"primaryProfession_arr\")))\n",
    "        )\n",
    "\n",
    "        .withColumn(\"knownForTitles_arr\", split_list(\"knownForTitles\"))\n",
    "        .withColumn(\n",
    "            \"knownForTitles\",\n",
    "            F.when(\n",
    "                F.col(\"knownForTitles_arr\").isNull(),\n",
    "                None\n",
    "            ).otherwise(F.concat_ws(\", \", F.col(\"knownForTitles_arr\")))\n",
    "        )\n",
    "\n",
    "        .dropDuplicates([\"nconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_name_basics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa73c567-2dec-41b0-9fa2-6086557d87b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_title_basics\",\n",
    "    comment=\"Cleaned title master (type, titles, years, runtime, genres).\"\n",
    ")\n",
    "def silver_title_basics():\n",
    "    df = read_bronze(\"bronze_title_basics\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"titleType\",      clean_string(\"titleType\"))\n",
    "        \n",
    "        .withColumn(\"primaryTitle\",   clean_name_or_title(\"primaryTitle\"))\n",
    "        .withColumn(\"originalTitle\",  clean_name_or_title(\"originalTitle\"))\n",
    "        .withColumn(\"isAdult\",        clean_int(\"isAdult\"))\n",
    "        .withColumn(\"startYear\",      clean_int(\"startYear\"))\n",
    "        .withColumn(\"endYear\",        clean_int(\"endYear\"))\n",
    "        .withColumn(\"runtimeMinutes\", clean_int(\"runtimeMinutes\"))\n",
    "\n",
    "        # ARRAY version for modeling / explode in gold\n",
    "        .withColumn(\"genres_arr\", split_list(\"genres\"))\n",
    "        # Optional pretty STRING version\n",
    "        .withColumn(\n",
    "            \"genres\",\n",
    "            F.when(\n",
    "                F.col(\"genres_arr\").isNull(),\n",
    "                None\n",
    "            ).otherwise(F.concat_ws(\", \", F.col(\"genres_arr\")))\n",
    "        )\n",
    "\n",
    "        .dropDuplicates([\"tconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_basics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f146291e-d6b8-4407-9d34-e0cf84987bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.expect_or_drop(\n",
    "    \"valid_tconst_in_crew\",\n",
    "    \"tconst IS NOT NULL\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew\",\n",
    "    comment=\"Cleaned title crew with director and writer lists.\"\n",
    ")\n",
    "def silver_title_crew():\n",
    "    df = read_bronze(\"bronze_title_crew\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"directors_arr\", split_list(\"directors\"))\n",
    "        .withColumn(\"writers_arr\",   split_list(\"writers\"))\n",
    "\n",
    "        .withColumn(\n",
    "            \"directors\",\n",
    "            F.when(F.col(\"directors_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"directors_arr\")))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"writers\",\n",
    "            F.when(F.col(\"writers_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"writers_arr\")))\n",
    "        )\n",
    "        .drop(\"directors_arr\", \"writers_arr\")\n",
    "\n",
    "        .dropDuplicates([\"tconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_crew\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a5e9a3a-dc05-4bc3-9c77-8f232e3dd4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.expect_or_drop(\n",
    "    \"valid_tconst_in_episode\",\n",
    "    \"tconst IS NOT NULL\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_episode\",\n",
    "    comment=\"Cleaned episode information (parent series, season, episode numbers).\"\n",
    ")\n",
    "def silver_title_episode():\n",
    "    df = read_bronze(\"bronze_title_episode\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"parentTconst\", clean_string(\"parentTconst\"))\n",
    "        .withColumn(\"seasonNumber\", clean_int(\"seasonNumber\"))\n",
    "        .withColumn(\"episodeNumber\", clean_int(\"episodeNumber\"))\n",
    "        .dropDuplicates([\"tconst\", \"parentTconst\", \"seasonNumber\", \"episodeNumber\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_episode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05cf93f0-7223-4ead-9c14-9fde8dd4d3af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import regexp_replace, col, trim, when\n",
    "\n",
    "@dlt.expect_or_drop(\n",
    "    \"valid_tconst_in_principals\",\n",
    "    \"tconst IS NOT NULL\"\n",
    ")\n",
    "@dlt.expect_or_drop(\n",
    "    \"valid_nconst_in_principals\",\n",
    "    \"nconst IS NOT NULL\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_principals\",\n",
    "    comment=\"Cleaned title principals with sanitized job and characters columns.\"\n",
    ")\n",
    "def silver_title_principals():\n",
    "\n",
    "    df = read_bronze(\"bronze_title_principals\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # ---------------------------------------------------\n",
    "        # CLEAN CHARACTERS: remove [ ] \\ \" and convert junk to NULL\n",
    "        # ---------------------------------------------------\n",
    "        .withColumn(\"characters\", regexp_replace(col(\"characters\"), r'\\\\', ''))     # remove backslashes\n",
    "        .withColumn(\"characters\", regexp_replace(col(\"characters\"), r'\"', ''))      # remove quotes\n",
    "        .withColumn(\"characters\", regexp_replace(col(\"characters\"), r'\\[|\\]', ''))  # remove brackets\n",
    "        .withColumn(\"characters\", trim(col(\"characters\")))\n",
    "        .withColumn(\n",
    "            \"characters\",\n",
    "            when(\n",
    "                col(\"characters\").isin(\"N\", \"null\", \"\"),   # after removing \"\\\" , \"\\N\" becomes \"N\"\n",
    "                None\n",
    "            ).otherwise(col(\"characters\"))\n",
    "        )\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # CLEAN JOB: turn \\N / N / '' / 'null' into NULL\n",
    "        # ---------------------------------------------------\n",
    "        .withColumn(\"job\", trim(col(\"job\")))\n",
    "        .withColumn(\n",
    "            \"job\",\n",
    "            when(\n",
    "                col(\"job\").isin(\"\\\\N\", \"N\", \"\", \"null\"),\n",
    "                None\n",
    "            ).otherwise(col(\"job\"))\n",
    "        )\n",
    "\n",
    "        # (Optional) CLEAN CATEGORY too, in case there are \\N values\n",
    "        .withColumn(\"category\", trim(col(\"category\")))\n",
    "        .withColumn(\n",
    "            \"category\",\n",
    "            when(\n",
    "                col(\"category\").isin(\"\\\\N\", \"N\", \"\", \"null\"),\n",
    "                None\n",
    "            ).otherwise(col(\"category\"))\n",
    "        )\n",
    "\n",
    "        # Make sure ordering is numeric\n",
    "        .withColumn(\"ordering\", col(\"ordering\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_principals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3132b600-6472-410d-88ba-dae989418c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.expect_or_drop(\n",
    "    \"valid_tconst_in_ratings\",\n",
    "    \"tconst IS NOT NULL\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_ratings\",\n",
    "    comment=\"Cleaned ratings (average rating and vote counts) per title.\"\n",
    ")\n",
    "def silver_title_ratings():\n",
    "    df = read_bronze(\"bronze_title_ratings\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"averageRating\", clean_double(\"averageRating\"))\n",
    "        .withColumn(\"numVotes\",      clean_int(\"numVotes\"))\n",
    "        .dropDuplicates([\"tconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06ef9b02-22ee-48cf-953f-e025677117af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.expect_or_drop(\n",
    "    \"valid_titleId_in_akas\",\n",
    "    \"titleId IS NOT NULL\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_akas\",\n",
    "    comment=\"Cleaned alternate titles with region/language codes and attributes.\"\n",
    ")\n",
    "def silver_title_akas():\n",
    "    df = read_bronze(\"bronze_title_akas\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"ordering\", clean_int(\"ordering\"))\n",
    "        .withColumn(\"region\",   clean_string(\"region\"))\n",
    "        .withColumn(\"language\", clean_string(\"language\"))\n",
    "\n",
    "        # arrays\n",
    "        .withColumn(\"types_arr\",      split_list(\"types\"))\n",
    "        .withColumn(\"attributes_arr\", split_list(\"attributes\"))\n",
    "\n",
    "        # strings\n",
    "        .withColumn(\n",
    "            \"types\",\n",
    "            F.when(F.col(\"types_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"types_arr\")))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"attributes\",\n",
    "            F.when(F.col(\"attributes_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"attributes_arr\")))\n",
    "        )\n",
    "        .drop(\"types_arr\", \"attributes_arr\")\n",
    "\n",
    "        .dropDuplicates([\"titleId\", \"ordering\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_akas\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
