{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9aa8bfc1-df47-4bd3-aed5-fd1b236c1907",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# =====================================================\n",
    "# HELPERS\n",
    "# =====================================================\n",
    "\n",
    "def read_bronze(table_name: str):\n",
    "    return dlt.read(table_name)\n",
    "\n",
    "def clean_int(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(F.col(col_name).cast(\"int\"))\n",
    "    )\n",
    "\n",
    "def clean_double(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(F.col(col_name).cast(\"double\"))\n",
    "    )\n",
    "\n",
    "def clean_string(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(F.trim(F.col(col_name)))\n",
    "    )\n",
    "\n",
    "def clean_name_or_title(col_name: str):\n",
    "    return (\n",
    "        F.when((F.col(col_name).isNull()) | (F.col(col_name) == \"\\\\N\"), None)\n",
    "         .otherwise(\n",
    "            F.trim(\n",
    "                F.regexp_replace(\n",
    "                    F.col(col_name),\n",
    "                    r'^[^A-Za-z0-9]+',  # remove junk at the start\n",
    "                    ''\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "def split_list(col_name: str):\n",
    "    \"\"\"\n",
    "    - Treats NULL, '\\\\N', and '' as NULL\n",
    "    - Splits comma-separated strings into arrays\n",
    "    - Removes empty elements; if array becomes empty -> NULL\n",
    "    \"\"\"\n",
    "    raw_col = F.col(col_name)\n",
    "\n",
    "    base_null = (\n",
    "        raw_col.isNull() |\n",
    "        (raw_col == \"\\\\N\") |\n",
    "        (F.trim(raw_col) == \"\")\n",
    "    )\n",
    "\n",
    "    arr = F.split(raw_col, \",\")\n",
    "    arr_clean = F.array_remove(arr, \"\")\n",
    "\n",
    "    return (\n",
    "        F.when(base_null, None)\n",
    "         .otherwise(\n",
    "            F.when(F.size(arr_clean) == 0, None).otherwise(arr_clean)\n",
    "         )\n",
    "    )\n",
    "\n",
    "def add_metadata(df, source):\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"src_table\", F.lit(source))\n",
    "        .withColumn(\"load_ts\", F.current_timestamp())\n",
    "        .withColumn(\"loaded_by\", F.current_user())\n",
    "    )\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: TITLE BASICS  (PK = tconst)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\n",
    "    \"valid_pk_tconst\",\n",
    "    \"tconst IS NOT NULL AND tconst <> '' AND tconst LIKE 'tt%'\"\n",
    ")\n",
    "@dlt.expect_or_drop(\n",
    "    \"valid_years\",\n",
    "    \"\"\"\n",
    "    (startYear IS NULL OR startYear BETWEEN 1870 AND 2025)\n",
    "    AND\n",
    "    (endYear IS NULL OR endYear BETWEEN 1870 AND 2025)\n",
    "    AND\n",
    "    (endYear IS NULL OR startYear IS NULL OR endYear >= startYear)\n",
    "    \"\"\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_basics\",\n",
    "    comment=\"Validated title master with clean dates and genres.\"\n",
    ")\n",
    "def silver_title_basics():\n",
    "    df = read_bronze(\"bronze_title_basics\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"titleType\",      clean_string(\"titleType\"))\n",
    "        .withColumn(\"primaryTitle\",   clean_name_or_title(\"primaryTitle\"))\n",
    "        .withColumn(\"originalTitle\",  clean_name_or_title(\"originalTitle\"))\n",
    "        .withColumn(\"isAdult\",        clean_int(\"isAdult\"))\n",
    "        .withColumn(\"startYear\",      clean_int(\"startYear\"))\n",
    "        .withColumn(\"endYear\",        clean_int(\"endYear\"))\n",
    "        .withColumn(\"runtimeMinutes\", clean_int(\"runtimeMinutes\"))\n",
    "\n",
    "        .withColumn(\"genres_arr\", split_list(\"genres\"))\n",
    "        .withColumn(\n",
    "            \"genres\",\n",
    "            F.when(F.col(\"genres_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"genres_arr\")))\n",
    "        )\n",
    "\n",
    "        .dropDuplicates([\"tconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_basics\")\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: NAME BASICS  (PK = nconst)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\n",
    "    \"valid_pk_nconst\",\n",
    "    \"nconst IS NOT NULL AND nconst <> '' AND nconst LIKE 'nm%'\"\n",
    ")\n",
    "@dlt.table(\n",
    "    name=\"silver_name_basics\",\n",
    "    comment=\"Validated people dimension with enforced PK.\"\n",
    ")\n",
    "def silver_name_basics():\n",
    "    df = read_bronze(\"bronze_name_basics\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"primaryName\", clean_name_or_title(\"primaryName\"))\n",
    "        .withColumn(\"birthYear\",   clean_int(\"birthYear\"))\n",
    "        .withColumn(\"deathYear\",   clean_int(\"deathYear\"))\n",
    "\n",
    "        .withColumn(\"primaryProfession_arr\", split_list(\"primaryProfession\"))\n",
    "        .withColumn(\n",
    "            \"primaryProfession\",\n",
    "            F.when(F.col(\"primaryProfession_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"primaryProfession_arr\")))\n",
    "        )\n",
    "\n",
    "        .withColumn(\"knownForTitles_arr\", split_list(\"knownForTitles\"))\n",
    "        .withColumn(\n",
    "            \"knownForTitles\",\n",
    "            F.when(F.col(\"knownForTitles_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"knownForTitles_arr\")))\n",
    "        )\n",
    "\n",
    "        .dropDuplicates([\"nconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_name_basics\")\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: TITLE PRINCIPALS (FK = tconst, nconst)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\"valid_fk_tconst\", \"tconst IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_fk_nconst\", \"nconst IS NOT NULL\")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_principals\",\n",
    "    comment=\"Validated cast/crew mapping with non-null FKs.\"\n",
    ")\n",
    "def silver_title_principals():\n",
    "    df = read_bronze(\"bronze_title_principals\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # clean characters: strip brackets/quotes, normalize blanks to NULL\n",
    "        .withColumn(\"characters\", F.regexp_replace(F.col(\"characters\"), r'[\\\\\\[\\]\\\"]', ''))\n",
    "        .withColumn(\"characters\", F.trim(F.col(\"characters\")))\n",
    "        .withColumn(\n",
    "            \"characters\",\n",
    "            F.when(\n",
    "                F.col(\"characters\").isin(\"\", \"null\", \"N\", \"\\\\N\"),\n",
    "                None\n",
    "            ).otherwise(F.col(\"characters\"))\n",
    "        )\n",
    "\n",
    "        .withColumn(\"job\",      clean_string(\"job\"))\n",
    "        .withColumn(\"category\", clean_string(\"category\"))\n",
    "        .withColumn(\"ordering\", clean_int(\"ordering\"))\n",
    "\n",
    "        .dropDuplicates([\"tconst\", \"nconst\", \"category\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_principals\")\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: TITLE CREW (FK = tconst)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\"valid_fk_tconst\", \"tconst IS NOT NULL\")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew\",\n",
    "    comment=\"Validated director/writer mapping.\"\n",
    ")\n",
    "def silver_title_crew():\n",
    "    df = read_bronze(\"bronze_title_crew\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"directors_arr\", split_list(\"directors\"))\n",
    "        .withColumn(\"writers_arr\",   split_list(\"writers\"))\n",
    "\n",
    "        .withColumn(\n",
    "            \"directors\",\n",
    "            F.when(F.col(\"directors_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"directors_arr\")))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"writers\",\n",
    "            F.when(F.col(\"writers_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"writers_arr\")))\n",
    "        )\n",
    "\n",
    "        .drop(\"directors_arr\", \"writers_arr\")\n",
    "        .dropDuplicates([\"tconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_crew\")\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: TITLE AKAS (FK = titleId)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\"valid_fk_titleId\", \"titleId IS NOT NULL\")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_akas\",\n",
    "    comment=\"Validated alternate titles with regions & languages.\"\n",
    ")\n",
    "def silver_title_akas():\n",
    "    df = read_bronze(\"bronze_title_akas\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"ordering\", clean_int(\"ordering\"))\n",
    "        .withColumn(\"region\",   clean_string(\"region\"))\n",
    "        .withColumn(\"language\", clean_string(\"language\"))\n",
    "\n",
    "        .withColumn(\"types_arr\",      split_list(\"types\"))\n",
    "        .withColumn(\"attributes_arr\", split_list(\"attributes\"))\n",
    "\n",
    "        .withColumn(\n",
    "            \"types\",\n",
    "            F.when(F.col(\"types_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"types_arr\")))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"attributes\",\n",
    "            F.when(F.col(\"attributes_arr\").isNull(), None)\n",
    "             .otherwise(F.concat_ws(\", \", F.col(\"attributes_arr\")))\n",
    "        )\n",
    "\n",
    "        .drop(\"types_arr\", \"attributes_arr\")\n",
    "        .dropDuplicates([\"titleId\", \"ordering\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_akas\")\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: TITLE EPISODE (FK = tconst)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\"valid_fk_tconst\", \"tconst IS NOT NULL\")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_episode\",\n",
    "    comment=\"Validated episodes with season/episode numbers.\"\n",
    ")\n",
    "def silver_title_episode():\n",
    "    df = read_bronze(\"bronze_title_episode\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"parentTconst\",  clean_string(\"parentTconst\"))\n",
    "        .withColumn(\"seasonNumber\",  clean_int(\"seasonNumber\"))\n",
    "        .withColumn(\"episodeNumber\", clean_int(\"episodeNumber\"))\n",
    "        .dropDuplicates([\"tconst\", \"parentTconst\", \"seasonNumber\", \"episodeNumber\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_episode\")\n",
    "\n",
    "# =====================================================\n",
    "# SILVER: TITLE RATINGS (FK = tconst)\n",
    "# =====================================================\n",
    "\n",
    "@dlt.expect_or_drop(\"valid_fk_tconst\", \"tconst IS NOT NULL\")\n",
    "@dlt.table(\n",
    "    name=\"silver_title_ratings\",\n",
    "    comment=\"Validated ratings per title.\"\n",
    ")\n",
    "def silver_title_ratings():\n",
    "    df = read_bronze(\"bronze_title_ratings\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"averageRating\", clean_double(\"averageRating\"))\n",
    "        .withColumn(\"numVotes\",      clean_int(\"numVotes\"))\n",
    "        .dropDuplicates([\"tconst\"])\n",
    "    )\n",
    "\n",
    "    return add_metadata(df_clean, \"bronze_title_ratings\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}